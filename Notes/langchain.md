---
date:
  2024-06-13
tags:
  - DL
  - LLM
---

<link rel="stylesheet" href="../style.css" />

# LangChain

`TODO`: [langchain wikidocs](https://wikidocs.net/233341)

## LLM

- LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ê³ ë ¤í•´ì•¼í•  ìš”ì†Œ
  - ë§¤ê°œ ë³€ìˆ˜ ì¡°ì •
  - í”„ë¡¬í”„íŠ¸ ë³´ê°•
  - ì‘ë‹µ ì¡°ì •
- <span class="_yellow _600">íŠ¹ì´ì </span>
  - LLMì€ ìƒíƒœë¥¼ ì €ì¥í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ëŒ€í™”ì˜ ì´ì „ ë©”ì‹œì§€ë¥¼ ê¸°ì–µí•  ìˆ˜ ì—†ìŒ
    - ê°œë°œìê°€ ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ê³  LLMì— ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ì•¼í•¨
  - LLMì€ ì¼ë¥ ì ì¸ ê·œì¹™ì´ ì—†ìŒ
    - ê°ì • ë¶„ì„, ë¶„ë¥˜, ì§ˆë¬¸ ë‹µë³€ê³¼ ìš”ì•½ ë“± ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— íŠ¹í™”ëœ ì—¬ëŸ¬ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•¨

## LLM ì•± êµ¬ì¶•ì„ ìœ„í•œ í†µí•© API ë ˆì´ì–´

- LangChain
  - LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬
  - Python ë° Typescript íŒ¨í‚¤ì§€ ì§€ì›
  - ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ LLM ê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í†µí•©ì„ ê°„ì†Œí™”í•˜ëŠ” SDK
  - ODBC<sup>[1](#odbc)</sup>
    - í‘œì¤€ SQL ë¬¸ì— ì§‘ì¤‘í•˜ê²Œ í•¨ìœ¼ë¡œì¨ ë°±ì—”ë“œ ë°ì´í„°ë² ì´ìŠ¤ì˜ êµ¬í˜„ ì„¸ë¶€ ì •ë³´ë¥¼ ìš”ì•½í•˜ëŠ” JDBC(Java Database Connectivity) ë“œë¼ì´ë²„ì™€ ìœ ì‚¬
  - ê°„ë‹¨í•˜ê³  í†µí•©ëœ APIë¥¼ ë…¸ì¶œí•˜ì—¬ ê¸°ë³¸ LLMì˜ êµ¬í˜„ ì„¸ë¶€ ì‚¬í•­ì„ ìš”ì•½í•¨
  - ê°œë°œìë“¤ì€ APIë¥¼ í†µí•´ ì½”ë“œë¥¼ í¬ê²Œ ë³€ê²½í•˜ì§€ ì•Šê³  ëª¨ë¸ì„ ì‰½ê²Œ êµì²´í•˜ê±°ë‚˜ ëŒ€ì²´í•¨

<figure>
    <img src="https://python.langchain.com/v0.2/svg/langchain_stack_dark.svg" alt="LangChain">
    <figcaption>[ì¶œì²˜] Introduction | ğŸ¦œğŸ§·LangChain python.langchain.com</figcaption>
</figure>

### LangChainì˜ LLM íë¦„ ì¡°ìœ¨

<img src="https://files.ciokorea.com/2023/08/Fixed_111.png" alt="LangChainì˜ LLM ì¡°ìœ¨ flow-chart">

- Data Sources ë°ì´í„° ì†ŒìŠ¤
  - ì• í”Œë¦¬ì¼€ì´ì…˜ì´ LLM ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ì™¸ë¶€ ì†ŒìŠ¤(PDF, ì›¹í˜ì´ì§€, CSV, ê´€ê³„í˜• DB)ì—ì„œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ìˆìŒ
  - ì„œë¡œ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ì— ì ‘ê·¼í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆê³¼ ì›í™œí•˜ê²Œ í†µí•©ë¨
- Word Embeddings ë‹¨ì–´ ì„ë² ë”©
  - ì¼ë¶€ ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•œ í›„, í…ìŠ¤íŠ¸ë¥¼ LLM ê´€ë ¨ ë‹¨ì–´ ì„ë² ë”© ëª¨ë¸ì— ì „ë‹¬ ($ex$ OpenAI CPT-3.5)
  - ì„ íƒí•œ LLMì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì„ë² ë”© ëª¨ë¸ì„ ì„ íƒí•¨
- Vector Database ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
  - ìƒì„±ëœ ì„ë² ë”©ì€ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìœ„í•´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë¨
  - ë©”ëª¨ë¦¬ ë‚´ ë°°ì—´ë¶€í„° íŒŒì¸ì½˜ <span class="_pink _italic">Pinecone</span> ê°™ì€ í˜¸ìŠ¤íŒ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë¥´ê¸°ê¹Œì§€ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë²¡í„°ë¥¼ ì‰½ê²Œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•¨
- LLM ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸
  - OpenAI, ì½”íˆì–´ Cohere, AI21ì´ ì œê³µí•˜ëŠ” ì£¼ë¥˜ LLMê³¼ í—ˆê¹…í˜ì´ìŠ¤ <span class="_pink _italic">Hugging Face</span>ì—ì„œ ì œê³µí•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ LLMì„ ì§€ì›

## LangChain êµ¬ì¡°

<img src="https://files.ciokorea.com/2023/08/Fixed_222.png" alt="LangChain Framework Architecture">

### Model I/O

- ëª¨ë¸ ì…ì¶œë ¥ ëª¨ë“ˆ
- LLMê³¼ì˜ ìƒí˜¸ ì‘ìš©
    - íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
    - ëª¨ë¸ API í˜¸ì¶œ
    - ê²°ê³¼ í•´ì„ ì§€ì›

### Data Connection

- ë°ì´í„° ì—°ê²° ëª¨ë“ˆ
- LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ETL íŒŒì´í”„ë¼ì¸
    - ì™¸ë¶€ ë¬¸ì„œ(PDF, ì—‘ì…€ íŒŒì¼ etc.) ë¡œë“œ
    - ë‹¨ì–´ ì„ë² ë”© ì¼ê´„ ë³€í™˜ ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    - ì¿¼ë¦¬ ê²€ìƒ‰
- LangChainì˜ ê°€ì¥ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œ

### Chains

- LLMê³¼ì˜ ìƒí˜¸ ì‘ìš©
    - ìœ ë‹‰ìŠ¤ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©ê³¼ ìœ ì‚¬
    - í•œ ëª¨ë“ˆì˜ ì¶œë ¥ì´ ë‹¤ë¥¸ ëª¨ë“ˆì— ì…ë ¥ìœ¼ë¡œ ì „ì†¡
    - ì›í•˜ëŠ” ê²°ê³¼ê°’ì„ ì–»ê¸° ìœ„í•´ LLMì˜ ì—¬ëŸ¬ ì‘ë‹µì„ ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì•¼ í•¨
- êµ¬ì„±ìš”ì†Œì™€ LLMì„ í™œìš©í•˜ì—¬ ì˜ˆìƒë˜ëŠ” ì‘ë‹µì„ ì–»ëŠ” íš¨ìœ¨ì ì¸ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ë„ë¡ ì„¤ê³„ë¨
- ë‹¨ìˆœ êµ¬ì¡° ì²´ì¸
    - í”„ë¡¬í”„íŠ¸ì™€ LLM í¬í•¨
- ë³µì¡ êµ¬ì¡° ì²´ì¸
    - LLMì„ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•¨(like ì¬ê·€ ë°©ì‹)
    - â‘ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ë‚´ìš©ì— ëŒ€í•´ â‘¡ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í”„ë¡¬í”„íŠ¸

### Memory

- ë©”ëª¨ë¦¬ ëª¨ë“ˆ
- ìƒíƒœ ë¹„ì €ì¥í˜•ì¸ LLM ëª¨ë¸ì— ë‹¨ê¸° ë° ì¥ê¸° ë©”ëª¨ë¦¬ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆë„ë¡ í•¨
- ë‹¨ê¸° ë©”ëª¨ë¦¬ (ê°„ë‹¨í•œ ë©”ì»¤ë‹ˆì¦˜)
    - ëŒ€í™” ê¸°ë¡ ìœ ì§€
- ì¥ê¸° ë©”ëª¨ë¦¬ (Redis ë“± ì™¸ë¶€ ì†ŒìŠ¤)
    - ë©”ì‹œì§€ ê¸°ë¡ ì €ì¥

### Callbacks

- LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê° ë‹¨ê³„ì— ê°œë°œìê°€ ì—°ê²°í•  ìˆ˜ ìˆëŠ” ì½œë°± ì‹œìŠ¤í…œ
- ë¡œê¹…, ëª¨ë‹ˆí„°ë§, ìŠ¤íŠ¸ë¦¬ë° ë° ê¸°íƒ€ ì‘ì—…ì— ìœ ìš©
- ì‚¬ìš©ì ì§€ì • ì½œë°± í•¸ë“¤ëŸ¬ ì‘ì„±
    - íŒŒì´í”„ë¼ì¸ ë‚´ì—ì„œ íŠ¹ì • ìƒí™©ì´ ë°œìƒí•  ë•Œ í˜¸ì¶œ
- ê¸°ë³¸ ì½œë°±
    - stdout
    - ëª¨ë“  ë‹¨ê³„ì˜ ì¶œë ¥ì„ ì½˜ì†”ì— ê°„ë‹¨íˆ ì¸ì‡„
    
### Agents

- ì¼ì¢…ì˜ ë™ì  ì²´ì¸
- LLMì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ í–‰ë™ ê³„íšìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ReAct í”„ë¡¬í”„íŠ¸(ì¶”ë¡ ê³¼ í–‰ë™) ì œì‘ì„ ë‹¨ìˆœí™”
- ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ì ì¸ ë™ì‘ì„ ì„ íƒí•˜ê¸° ìœ„í•´ LLMì„ ì‚¬ìš©
    - ë™ì‘ì˜ ìˆœì„œëŠ” Chain(ì½”ë“œ)ì„ í†µí•´ í•˜ë“œ ì½”ë”©í•¨
- ì—ì´ì „íŠ¸ëŠ” ì–¸ì–´ ëª¨ë¸ì„ ì¶”ë¡ ì—”ì§„ìœ¼ë¡œ ì‚¬ìš©
    - ì–´ë–¤ ìˆœì„œë¡œ ì–´ë–¤ ë™ì‘ì„ ì·¨í• ì§€ ê²°ì •í•¨

---

## Tutorials

### Build a Simple LLM Application with LCEL

<details>
<summary class="_bgblue"></summary>

#### 1. Setup

```bash
pip install langchain
```

<span class="_pinksmall">ğŸ’— LangSmith Config í™˜ê²½ ë³€ìˆ˜ ì„¤ì •</span>

- CLI

```bash
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
```

- Source Code

```python
import getpass
import os

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
# os.environ["LANGCHAIN_API_KEY"] = "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"
```

#### 2. Using Language Models

<details>
  <summary class="_pinksmall">Cohere?</summary>

- Langchain Docs Tutorialì˜ Default ëª¨ë¸ì€ OpenAI `gpt-4.0`
  - OpanAI API ê¸°ë³¸ credit 3ê°œì›” ê¸°í•œ ë§Œë£Œë¡œ ì‚¬ìš© ë¶ˆê°€
- ëŒ€ì‹  <span class="_yellow _italic">Cohere Trial Key</span> ë°œê¸‰ ì‚¬ìš©
</details>

```bash
pip install -qU langchain-cohere
```

```python
import getpass
import os

os.environ["COHERE_API_KEY"] = getpass.getpass()
# os.environ["COHERE_API_KEY"] = "4BtT07HreyYG7DWIcOPYRq5jwU5lBEW8VkUzaBNZ"
```

```python
from langchain_cohere import ChatCohere

# LangChain "Runnables"
model = ChatCohere(model="command-r")
```

```python
from langchain_core.messages import HumanMessage, SystemMessage

messages = [
    SystemMessage(content="Translate the following from English into Italian"),
    HumanMessage(content="hi!"),
]

model.invoke(messages)
```

```python
AIMessage(content='ciao!', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 14, 'total_tokens': 17}, 'model_name': 'command-r'}, id='run-c8071053-c633-4d16-b356-68e632731c71')
```

#### 3. OutputParsers
```python
from langchain_core.output_parsers import StrOutputParser

result = model.invoke(message)

parser = StrOutputParser()
parser.invoke(result)
```
```python
'Ciao!'
```
```python
chain = model | parser
chain.invoke(message)
```
```python
'Ciao!'
```

#### 4. Prompt Templates
- `language`: The language to translate text into
- `text`: The text to translate

```python
from langchain_core.prompts import ChatPromptTemplate

system_template = "Translate the following into {language}:"
prompt_template = ChatPromptTemplate.from_messages(
  [("system", system_template), ("user", "{text}")]
)

result = prompt_template.invoke({"language": "italian", "text": "hi"})
```
```python
ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='hi')])
```
```python
result.to_messages()
```
```python
[SystemMessage(content='Translate the following into italian:'),
 HumanMessage(content='hi')]
```

#### 5. Chaining together components with LCEL
- `LangChain Expression Language`
- The `|` operator is used in LangChain to combine two elements together.

```python
chain = prompt_template | model | parser
chain.invoke({"language": "italian", "text": "hi"})
```
```python
'Ciao!'
```

#### Final

```bash
pip install langchain
pip install -qU langchain-cohere
```

```python
import os

# í™˜ê²½ë³€ìˆ˜ êµ¬ì„±
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "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"
os.environ["COHERE_API_KEY"] = "4BtT07HreyYG7DWIcOPYRq5jwU5lBEW8VkUzaBNZ"

from langchain_cohere import ChatCohere
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
system_template = "Translate the following into {language}:"
prompt_template = ChatPromptTemplate.from_messages(
    [("system", system_template), ("user", "{text}")]
)
# ëª¨ë¸ ê°ì²´ í˜¸ì¶œ
model = ChatCohere(model="command-r")
# ì‘ë‹µ íŒŒì‹± ê°ì²´ ìƒì„±
parser = StrOutputParser()
# ì²´ì¸ êµ¬ì„±
chain = prompt_template | model | parser
# ì²´ì¸ ì‹¤í–‰
chain.invoke({"language": "italian", "text": "hi"})
```

```python
'Ciao!'
```
</details>


### Build a Chatbot

#### Concepts

- Have a conversation
- Remember previous interactions

<details>
  <summary class="_bgblue"></summary>

#### 1. Setup

</details>

### Build a Retrieval Augmented Generation (RAG) App

<details>
  <summary class="">ğŸ’« RAGì´ë€?</summary>
  LLM ì§€ì‹ì„ ì¶”ê°€ ë°ì´í„°ë¡œ ë³´ê°•í•˜ëŠ” ê¸°ìˆ  <span class="_pinksmall">ê²€ìƒ‰ ì¦ê°• ìƒì„±</span><br>
  LLMì€ ê´‘ë²”ìœ„í•œ ì£¼ì œì— ëŒ€í•´ ì¶”ë¡ í•  ìˆ˜ ìˆì§€ë§Œ, ì§€ì‹ì€ í•™ìŠµëœ íŠ¹ì • ì‹œì ê¹Œì§€ì˜ ê³µê°œ ë°ì´í„°ì— êµ­í•œë¨<br>
  ê°œì¸ ë°ì´í„° ë˜ëŠ” ëª¨ë¸ì˜ ì»·ì˜¤í”„ ë‚ ì§œ ì´í›„ì— ë„ì…ëœ ë°ì´í„°ì— ëŒ€í•´ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ë ¤ë©´ ëª¨ë¸ì— í•„ìš”í•œ íŠ¹ì • ì •ë³´ë¡œ ëª¨ë¸ì˜ ì§€ì‹ì„ ë³´ê°•í•´ì•¼ í•¨<br>
  ì ì ˆí•œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ ëª¨ë¸ í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•˜ëŠ” ê³¼ì •<br>
  â†’ <code>RAG</code>(Retrieve Augmented Generation)
</details>

#### Concepts

- **Indexing**
  - 1. *Load*
  - 2. *Split*
  - 3. *Store*
- **Retrieval and generation**
  - 4. *Retrieval*
  - 5. *Generation*

#### Setup

<details>
  <summary class="_bgblue"></summary>

```bash
pip install langchain
pip install -qU langchain-cohere
```
```python
import os

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "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"
os.environ["COHERE_API_KEY"] = "4BtT07HreyYG7DWIcOPYRq5jwU5lBEW8VkUzaBNZ"
```
</details>

#### Preview

<details>
  <summary class="_bgblue"></summary>

```python
from langchain_cohere import ChatCohere

llm = ChatCohere(model="command-r")
```

```python
import bs4
from langchain import hub
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_cohere import CohereEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# Load, chunk and index the contents of the blog.
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)
docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
vectorstore = Chroma.from_documents(documents=splits, embedding=CohereEmbeddings())

# Retrieve and generate using the relevant snippets of the blog.
retriever = vectorstore.as_retriever()
prompt = hub.pull("rlm/rag-prompt")


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

rag_chain.invoke("What is Task Decomposition?")
```

```python
# cleanup
vectorstore.delete_collection()
```
</details>

#### Detailed Walkthrough
<details>
  <summary class="_bgblue"></summary>


##### 1. Indexing: Load

```python
import bs4
from langchain_community.document_loaders import WebBaseLoader

# Only keep post title, headers, and content from the full HTML.
bs4_strainer = bs4.SoupStrainer(class_=("post-title", "post-header", "post-content"))
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs={"parse_only": bs4_strainer},
)
docs = loader.load()

len(docs[0].page_content)
```

```python
print(docs[0].page_content[:500])
```

##### 2. Indexing: Split

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200, add_start_index=True
)
all_splits = text_splitter.split_documents(docs)

len(all_splits)
```
```python
len(all_splits[0].page_content)
```
```python
all_splits[10].metadata
```
##### 3. Indexing: Store
```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

##### 4. Retrieval and Generation: Retrieve
```python
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 6})

retrieved_docs = retriever.invoke("What are the approaches to Task Decomposition?")

len(retrieved_docs)
```
```python
print(retrieved_docs[0].page_content)
```

##### 5. Retrieval and Generation: Generate
```bash
pip install langchain
pip install -qU langchain-cohere
```
```python
import os

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "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"
os.environ["COHERE_API_KEY"] = "4BtT07HreyYG7DWIcOPYRq5jwU5lBEW8VkUzaBNZ"
```
```python
from langchain_cohere import ChatCohere

llm = ChatCohere(model="command-r")
```
```python
from langchain import hub

prompt = hub.pull("rlm/rag-prompt")

example_messages = prompt.invoke(
    {"context": "filler context", "question": "filler question"}
).to_messages()

print(example_messages)
```
```python
print(example_messages[0].content)
```
</details>


# *Reference*

[LangChain ì¹¼ëŸ¼](https://www.ciokorea.com/column/305341#csidxb23f99cd3f147a1b27c8968f282a5a0 )  
[LangChain Docs](https://python.langchain.com/v0.2/docs/introduction/)

# *Footnotes*

<a name="odbc" class="_footnote">1.</a> Open DataBase Connectivity  
ì‘ìš©í”„ë¡œê·¸ë¨ <span class="_pink _italic">HeidiSQL, SQLyog, etc.</span>ì—ì„œ ë°ì´í„° ì ‘ê·¼ í•  ë•Œ ì–´ë– í•œ DBMS <span class="_pink _italic">Oracle, MySQL, MariaDB, etc.</span>ì— ì˜í•´ ê´€ë¦¬ë˜ê³  ìˆëŠ”ì§€ ì˜ì‹í•  í•„ìš”ê°€ ì—†ìŒ
