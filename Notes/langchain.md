---
date:
  2024-06-13
tags:
  - DL
  - LLM
---

<link rel="stylesheet" href="../Assets/style.css" />

# LangChain

`TODO`: [langchain wikidocs](https://wikidocs.net/233341)

## LLM

- LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ê³ ë ¤í•´ì•¼í•  ìš”ì†Œ
  - ë§¤ê°œ ë³€ìˆ˜ ì¡°ì •
  - í”„ë¡¬í”„íŠ¸ ë³´ê°•
  - ì‘ë‹µ ì¡°ì •
- <span class="_yellow _600">íŠ¹ì´ì </span>
  - LLMì€ ìƒíƒœë¥¼ ì €ì¥í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ëŒ€í™”ì˜ ì´ì „ ë©”ì‹œì§€ë¥¼ ê¸°ì–µí•  ìˆ˜ ì—†ìŒ
    - ê°œë°œìê°€ ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ê³  LLMì— ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ì•¼í•¨
  - LLMì€ ì¼ë¥ ì ì¸ ê·œì¹™ì´ ì—†ìŒ
    - ê°ì • ë¶„ì„, ë¶„ë¥˜, ì§ˆë¬¸ ë‹µë³€ê³¼ ìš”ì•½ ë“± ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— íŠ¹í™”ëœ ì—¬ëŸ¬ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•¨

## LLM ì•± êµ¬ì¶•ì„ ìœ„í•œ í†µí•© API ë ˆì´ì–´

- LangChain
  - LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬
  - Python ë° Typescript íŒ¨í‚¤ì§€ ì§€ì›
  - ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ LLM ê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í†µí•©ì„ ê°„ì†Œí™”í•˜ëŠ” SDK
  - ODBC<sup>[1](#odbc)</sup>
    - í‘œì¤€ SQL ë¬¸ì— ì§‘ì¤‘í•˜ê²Œ í•¨ìœ¼ë¡œì¨ ë°±ì—”ë“œ ë°ì´í„°ë² ì´ìŠ¤ì˜ êµ¬í˜„ ì„¸ë¶€ ì •ë³´ë¥¼ ìš”ì•½í•˜ëŠ” JDBC(Java Database Connectivity) ë“œë¼ì´ë²„ì™€ ìœ ì‚¬
  - ê°„ë‹¨í•˜ê³  í†µí•©ëœ APIë¥¼ ë…¸ì¶œí•˜ì—¬ ê¸°ë³¸ LLMì˜ êµ¬í˜„ ì„¸ë¶€ ì‚¬í•­ì„ ìš”ì•½í•¨
  - ê°œë°œìë“¤ì€ APIë¥¼ í†µí•´ ì½”ë“œë¥¼ í¬ê²Œ ë³€ê²½í•˜ì§€ ì•Šê³  ëª¨ë¸ì„ ì‰½ê²Œ êµì²´í•˜ê±°ë‚˜ ëŒ€ì²´í•¨

<figure>
    <img src="https://python.langchain.com/v0.2/svg/langchain_stack_dark.svg" alt="LangChain">
    <figcaption>[ì¶œì²˜] Introduction | ğŸ¦œğŸ§·LangChain python.langchain.com</figcaption>
</figure>

### LangChainì˜ LLM íë¦„ ì¡°ìœ¨

<img src="https://files.ciokorea.com/2023/08/Fixed_111.png" alt="LangChainì˜ LLM ì¡°ìœ¨ flow-chart">

- Data Sources ë°ì´í„° ì†ŒìŠ¤
  - ì• í”Œë¦¬ì¼€ì´ì…˜ì´ LLM ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ì™¸ë¶€ ì†ŒìŠ¤(PDF, ì›¹í˜ì´ì§€, CSV, ê´€ê³„í˜• DB)ì—ì„œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ìˆìŒ
  - ì„œë¡œ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ì— ì ‘ê·¼í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆê³¼ ì›í™œí•˜ê²Œ í†µí•©ë¨
- Word Embeddings ë‹¨ì–´ ì„ë² ë”©
  - ì¼ë¶€ ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•œ í›„, í…ìŠ¤íŠ¸ë¥¼ LLM ê´€ë ¨ ë‹¨ì–´ ì„ë² ë”© ëª¨ë¸ì— ì „ë‹¬ ($ex$ OpenAI CPT-3.5)
  - ì„ íƒí•œ LLMì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì„ë² ë”© ëª¨ë¸ì„ ì„ íƒí•¨
- Vector Database ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
  - ìƒì„±ëœ ì„ë² ë”©ì€ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìœ„í•´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë¨
  - ë©”ëª¨ë¦¬ ë‚´ ë°°ì—´ë¶€í„° íŒŒì¸ì½˜ <span class="_pink _italic">Pinecone</span> ê°™ì€ í˜¸ìŠ¤íŒ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë¥´ê¸°ê¹Œì§€ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë²¡í„°ë¥¼ ì‰½ê²Œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•¨
- LLM ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸
  - OpenAI, ì½”íˆì–´ Cohere, AI21ì´ ì œê³µí•˜ëŠ” ì£¼ë¥˜ LLMê³¼ í—ˆê¹…í˜ì´ìŠ¤ <span class="_pink _italic">Hugging Face</span>ì—ì„œ ì œê³µí•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ LLMì„ ì§€ì›

## LangChain êµ¬ì¡°

<img src="https://files.ciokorea.com/2023/08/Fixed_222.png" alt="LangChain Framework Architecture">

### Model I/O

- ëª¨ë¸ ì…ì¶œë ¥ ëª¨ë“ˆ
- LLMê³¼ì˜ ìƒí˜¸ ì‘ìš©
    - íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
    - ëª¨ë¸ API í˜¸ì¶œ
    - ê²°ê³¼ í•´ì„ ì§€ì›

### Data Connection

- ë°ì´í„° ì—°ê²° ëª¨ë“ˆ
- LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ETL íŒŒì´í”„ë¼ì¸
    - ì™¸ë¶€ ë¬¸ì„œ(PDF, ì—‘ì…€ íŒŒì¼ etc.) ë¡œë“œ
    - ë‹¨ì–´ ì„ë² ë”© ì¼ê´„ ë³€í™˜ ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    - ì¿¼ë¦¬ ê²€ìƒ‰
- LangChainì˜ ê°€ì¥ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œ

### Chains

- LLMê³¼ì˜ ìƒí˜¸ ì‘ìš©
    - ìœ ë‹‰ìŠ¤ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©ê³¼ ìœ ì‚¬
    - í•œ ëª¨ë“ˆì˜ ì¶œë ¥ì´ ë‹¤ë¥¸ ëª¨ë“ˆì— ì…ë ¥ìœ¼ë¡œ ì „ì†¡
    - ì›í•˜ëŠ” ê²°ê³¼ê°’ì„ ì–»ê¸° ìœ„í•´ LLMì˜ ì—¬ëŸ¬ ì‘ë‹µì„ ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì•¼ í•¨
- êµ¬ì„±ìš”ì†Œì™€ LLMì„ í™œìš©í•˜ì—¬ ì˜ˆìƒë˜ëŠ” ì‘ë‹µì„ ì–»ëŠ” íš¨ìœ¨ì ì¸ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ë„ë¡ ì„¤ê³„ë¨
- ë‹¨ìˆœ êµ¬ì¡° ì²´ì¸
    - í”„ë¡¬í”„íŠ¸ì™€ LLM í¬í•¨
- ë³µì¡ êµ¬ì¡° ì²´ì¸
    - LLMì„ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•¨(like ì¬ê·€ ë°©ì‹)
    - â‘ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ë‚´ìš©ì— ëŒ€í•´ â‘¡ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í”„ë¡¬í”„íŠ¸

### Memory

- ë©”ëª¨ë¦¬ ëª¨ë“ˆ
- ìƒíƒœ ë¹„ì €ì¥í˜•ì¸ LLM ëª¨ë¸ì— ë‹¨ê¸° ë° ì¥ê¸° ë©”ëª¨ë¦¬ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆë„ë¡ í•¨
- ë‹¨ê¸° ë©”ëª¨ë¦¬ (ê°„ë‹¨í•œ ë©”ì»¤ë‹ˆì¦˜)
    - ëŒ€í™” ê¸°ë¡ ìœ ì§€
- ì¥ê¸° ë©”ëª¨ë¦¬ (Redis ë“± ì™¸ë¶€ ì†ŒìŠ¤)
    - ë©”ì‹œì§€ ê¸°ë¡ ì €ì¥

### Callbacks

- LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê° ë‹¨ê³„ì— ê°œë°œìê°€ ì—°ê²°í•  ìˆ˜ ìˆëŠ” ì½œë°± ì‹œìŠ¤í…œ
- ë¡œê¹…, ëª¨ë‹ˆí„°ë§, ìŠ¤íŠ¸ë¦¬ë° ë° ê¸°íƒ€ ì‘ì—…ì— ìœ ìš©
- ì‚¬ìš©ì ì§€ì • ì½œë°± í•¸ë“¤ëŸ¬ ì‘ì„±
    - íŒŒì´í”„ë¼ì¸ ë‚´ì—ì„œ íŠ¹ì • ìƒí™©ì´ ë°œìƒí•  ë•Œ í˜¸ì¶œ
- ê¸°ë³¸ ì½œë°±
    - stdout
    - ëª¨ë“  ë‹¨ê³„ì˜ ì¶œë ¥ì„ ì½˜ì†”ì— ê°„ë‹¨íˆ ì¸ì‡„
    
### Agents

- ì¼ì¢…ì˜ ë™ì  ì²´ì¸
- LLMì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ í–‰ë™ ê³„íšìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ReAct í”„ë¡¬í”„íŠ¸(ì¶”ë¡ ê³¼ í–‰ë™) ì œì‘ì„ ë‹¨ìˆœí™”
- ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ì ì¸ ë™ì‘ì„ ì„ íƒí•˜ê¸° ìœ„í•´ LLMì„ ì‚¬ìš©
    - ë™ì‘ì˜ ìˆœì„œëŠ” Chain(ì½”ë“œ)ì„ í†µí•´ í•˜ë“œ ì½”ë”©í•¨
- ì—ì´ì „íŠ¸ëŠ” ì–¸ì–´ ëª¨ë¸ì„ ì¶”ë¡ ì—”ì§„ìœ¼ë¡œ ì‚¬ìš©
    - ì–´ë–¤ ìˆœì„œë¡œ ì–´ë–¤ ë™ì‘ì„ ì·¨í• ì§€ ê²°ì •í•¨

---

## Tutorials

### Build a Simple LLM Application with LCEL

<details>
<summary class="_bgblue"></summary>

#### 1. Setup

```bash
pip install langchain
```

<span class="_pinksmall">ğŸ’— LangSmith Config í™˜ê²½ ë³€ìˆ˜ ì„¤ì •</span>

- CLI

```bash
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
```

- pkg 1. `getpass`
  - console ì°½ì—ì„œ ì§ì ‘ ì…ë ¥

```python
import os
import getpass

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

- pkg 2. `dotenv`
  - .env íŒŒì¼ í˜¸ì¶œ

```bash
pip install python-dotenv
```

```python
from dotenv import find_dotenv, load_dotenv

dotenv_path = find_dotenv("../Assets/.env")
assert load_dotenv(dotenv_path=dotenv_path), "`.env` file cannot found."
```

#### 2. Using Language Models

<details>
  <summary class="_pinksmall">Cohere?</summary>

- Langchain Docs Tutorialì˜ Default ëª¨ë¸ì€ OpenAI `gpt-4.0`
  - OpanAI API ê¸°ë³¸ credit 3ê°œì›” ê¸°í•œ ë§Œë£Œë¡œ ì‚¬ìš© ë¶ˆê°€
- ëŒ€ì‹  <span class="_yellow _italic">Cohere Trial Key</span> ë°œê¸‰ ì‚¬ìš©
</details>

```bash
pip install -qU langchain-cohere
```

```python
from dotenv import find_dotenv, load_dotenv

dotenv_path = find_dotenv("../Assets/.env")
assert load_dotenv(dotenv_path=dotenv_path), "`.env` file cannot found."
```

```python
from langchain_cohere import ChatCohere

# LangChain "Runnables"
model = ChatCohere(model="command-r")
```

```python
from langchain_core.messages import HumanMessage, SystemMessage

messages = [
    SystemMessage(content="Translate the following from English into Italian"),
    HumanMessage(content="hi!"),
]

model.invoke(messages)
```

```console
AIMessage(content='ciao!', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 14, 'total_tokens': 17}, 'model_name': 'command-r'}, id='run-c8071053-c633-4d16-b356-68e632731c71')
```

#### 3. OutputParsers

```python
from langchain_core.output_parsers import StrOutputParser

result = model.invoke(message)

parser = StrOutputParser()
parser.invoke(result)
```

```console
'Ciao!'
```

```python
chain = model | parser
chain.invoke(message)
```

```console
'Ciao!'
```

#### 4. Prompt Templates

- `language`: The language to translate text into
- `text`: The text to translate

```python
from langchain_core.prompts import ChatPromptTemplate

system_template = "Translate the following into {language}:"
prompt_template = ChatPromptTemplate.from_messages(
  [("system", system_template), ("user", "{text}")]
)

result = prompt_template.invoke({"language": "italian", "text": "hi"})
```

```console
ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='hi')])
```

```python
result.to_messages()
```

```console
[SystemMessage(content='Translate the following into italian:'),
 HumanMessage(content='hi')]
```

#### 5. Chaining together components with LCEL

- `LangChain Expression Language`
- The `|` operator is used in LangChain to combine two elements together.

```python
chain = prompt_template | model | parser
chain.invoke({"language": "italian", "text": "hi"})
```

```console
'Ciao!'
```

#### Final

```bash
pip install langchain
pip install -qU langchain-cohere
```

```python
# í™˜ê²½ë³€ìˆ˜ êµ¬ì„±
from dotenv import find_dotenv, load_dotenv

dotenv_path = find_dotenv("../Assets/.env")
assert load_dotenv(dotenv_path=dotenv_path), "`.env` file cannot found."

from langchain_cohere import ChatCohere
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
system_template = "Translate the following into {language}:"
prompt_template = ChatPromptTemplate.from_messages(
    [("system", system_template), ("user", "{text}")]
)
# ëª¨ë¸ ê°ì²´ í˜¸ì¶œ
model = ChatCohere(model="command-r")
# ì‘ë‹µ íŒŒì‹± ê°ì²´ ìƒì„±
parser = StrOutputParser()
# ì²´ì¸ êµ¬ì„±
chain = prompt_template | model | parser
# ì²´ì¸ ì‹¤í–‰
chain.invoke({"language": "italian", "text": "hi"})
```

```console
'Ciao!'
```
</details>

### Build a Chatbot

#### Concepts

- Have a conversation
- Remember previous interactions

<details>
  <summary class="_bgblue"></summary>

#### 1. Setup

</details>

### Build a Retrieval Augmented Generation (RAG) App

<details>
  <summary class="">ğŸ’« RAGì´ë€?</summary>
  LLM ì§€ì‹ì„ ì¶”ê°€ ë°ì´í„°ë¡œ ë³´ê°•í•˜ëŠ” ê¸°ìˆ  <span class="_pinksmall">ê²€ìƒ‰ ì¦ê°• ìƒì„±</span><br>
  LLMì€ ê´‘ë²”ìœ„í•œ ì£¼ì œì— ëŒ€í•´ ì¶”ë¡ í•  ìˆ˜ ìˆì§€ë§Œ, ì§€ì‹ì€ í•™ìŠµëœ íŠ¹ì • ì‹œì ê¹Œì§€ì˜ ê³µê°œ ë°ì´í„°ì— êµ­í•œë¨<br>
  ê°œì¸ ë°ì´í„° ë˜ëŠ” ëª¨ë¸ì˜ ì»·ì˜¤í”„ ë‚ ì§œ ì´í›„ì— ë„ì…ëœ ë°ì´í„°ì— ëŒ€í•´ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ë ¤ë©´ ëª¨ë¸ì— í•„ìš”í•œ íŠ¹ì • ì •ë³´ë¡œ ëª¨ë¸ì˜ ì§€ì‹ì„ ë³´ê°•í•´ì•¼ í•¨<br>
  ì ì ˆí•œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ ëª¨ë¸ í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•˜ëŠ” ê³¼ì •<br>
  â†’ <code>RAG</code>(Retrieve Augmented Generation)
</details>

#### Concepts

- **Indexing**
  - 1. *Load*
  - 2. *Split*
  - 3. *Store*
- **Retrieval and generation**
  - 4. *Retrieval*
  - 5. *Generation*

#### Setup

<details>
  <summary class="_bgblue"></summary>

```bash
pip install langchain
pip install -qU langchain-cohere
```

```python
from dotenv import find_dotenv, load_dotenv

dotenv_path = find_dotenv("../Assets/.env")
assert load_dotenv(dotenv_path=dotenv_path), "`.env` file cannot found."
```
</details>

#### Preview

<details>
  <summary class="_bgblue"></summary>

```python
from langchain_cohere import ChatCohere

llm = ChatCohere(model="command-r")
```

```bash
pip install beautifulsoup4
```

<details>
    <summary class="_pinksmall">$if$ `langchain_chroma` Module Error occured</summary>
    
```bash
pip install langchain_chroma
```
</details>

```python
import bs4
from langchain import hub
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_cohere import CohereEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# Load, chunk and index the contents of the blog.
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)
docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
vectorstore = Chroma.from_documents(documents=splits, embedding=CohereEmbeddings())

# Retrieve and generate using the relevant snippets of the blog.
retriever = vectorstore.as_retriever()
prompt = hub.pull("rlm/rag-prompt")


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

rag_chain.invoke("What is Task Decomposition?")
```

```python
"Task decomposition is a process that involves breaking down complicated tasks into simpler, more manageable steps to aid an agent's planning process. It can be executed by an LLM with specific prompts, using task-specific instructions, or with human input. This technique helps enhance model performance and provides insight into the model's thought process."
```

```python
# cleanup
vectorstore.delete_collection()
```
</details>

#### Detailed Walkthrough

<details>
  <summary class="_bgblue"></summary>

##### 1. Indexing: Load

```python
import bs4
from langchain_community.document_loaders import WebBaseLoader

# Only keep post title, headers, and content from the full HTML.
bs4_strainer = bs4.SoupStrainer(class_=("post-title", "post-header", "post-content"))
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs={"parse_only": bs4_strainer},
)
docs = loader.load()

len(docs[0].page_content)
```

```python
43131
```

```python
print(docs[0].page_content[:500])
```

```python


      LLM Powered Autonomous Agents
    
Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng


Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.
Agent System Overview#
In
```

##### 2. Indexing: Split

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200, add_start_index=True
)
all_splits = text_splitter.split_documents(docs)

len(all_splits)
```

```python
66
```

```python
len(all_splits[0].page_content)
```

```python
969
```

```python
all_splits[10].metadata
```

```python
{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',
 'start_index': 7056}
```

##### 3. Indexing: Store
```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

##### 4. Retrieval and Generation: Retrieve

```python
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 6})

retrieved_docs = retriever.invoke("What are the approaches to Task Decomposition?")

len(retrieved_docs)
```

```python
6
```

```python
print(retrieved_docs[0].page_content)
```

```python
Fig. 1. Overview of a LLM-powered autonomous agent system.
Component One: Planning#
A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.
Task Decomposition#
Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to â€œthink step by stepâ€ to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the modelâ€™s thinking process.
```

##### 5. Retrieval and Generation: Generate

```bash
pip install langchain
pip install -qU langchain-cohere
```

```python
from dotenv import find_dotenv, load_dotenv

dotenv_path = find_dotenv("../Assets/.env")
assert load_dotenv(dotenv_path=dotenv_path), "`.env` file cannot found."
```

```python
from langchain_cohere import ChatCohere

llm = ChatCohere(model="command-r")
```

```python
from langchain import hub

prompt = hub.pull("rlm/rag-prompt")

example_messages = prompt.invoke(
    {"context": "filler context", "question": "filler question"}
).to_messages()

example_messages
```

```python
[HumanMessage(content="You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: filler question \nContext: filler context \nAnswer:")]
```

```python
print(example_messages[0].content)
```

```python
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: filler question 
Context: filler context 
Answer:
```

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

for chunk in rag_chain.stream("What is Task Decomposition?"):
    print(chunk, end="", flush=True)
```

```python
Task decomposition is a process that involves breaking down complex tasks into simpler, more manageable steps to make them easier to complete. This can be done in several ways, including prompting a LLM, using task-specific instructions, or seeking human input. It's a useful technique to help agents plan and execute tasks effectively.Task decomposition is a process that involves breaking down complex tasks into simpler, more manageable steps to make them easier to complete. This can be done in several ways, including prompting a LLM, using task-specific instructions, or seeking human input. It's a useful technique to help agents plan and execute tasks effectively.
```

<span class="_pinksmall">ğŸ’— Built-in Chains</span>

```python
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

system_prompt = (
    "You are an assistant for question-answering tasks. "
    "Use the following pieces of retrieved context to answer "
    "the question. If you don't know the answer, say that you "
    "don't know. Use three sentences maximum and keep the "
    "answer concise."
    "\n\n"
    "{context}"
)

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}"),
    ]
)


question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, question_answer_chain)

response = rag_chain.invoke({"input": "What is Task Decomposition?"})
print(response["answer"])
```

```python
Task decomposition is a process that breaks down complicated tasks into simpler, more manageable steps. This makes it easier for agents to plan and execute tasks by tackling smaller, more feasible objectives. There are several ways to achieve task decomposition, such as using simple prompts, task-specific instructions, or even human inputs.
```

```python
for document in response["context"]:
    print(document)
    print()
```

```python
page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\nComponent One: Planning#\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\nTask Decomposition#\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to â€œthink step by stepâ€ to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the modelâ€™s thinking process.' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}

page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\nTask decomposition can be done (1) by LLM with simple prompting like "Steps for XYZ.\\n1.", "What are the subgoals for achieving XYZ?", (2) by using task-specific instructions; e.g. "Write a story outline." for writing a novel, or (3) with human inputs.' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}

page_content='Resources:\n1. Internet access for searches and information gathering.\n2. Long Term memory management.\n3. GPT-3.5 powered Agents for delegation of simple tasks.\n4. File output.\n\nPerformance Evaluation:\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n2. Constructively self-criticize your big-picture behavior constantly.\n3. Reflect on past decisions and strategies to refine your approach.\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 29630}

page_content="(3) Task execution: Expert models execute on the specific tasks and log results.\nInstruction:\n\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path." metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19373}

page_content='The AI assistant can parse user input to several tasks: [{"task": task, "id", task_id, "dep": dependency_task_ids, "args": {"text": text, "image": URL, "audio": URL, "video": URL}}]. The "dep" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag "-task_id" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17804}

page_content='Case Studies#\nScientific Discovery Agent#\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\n\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 22305}
```

```python
from langchain_core.prompts import PromptTemplate

template = """Use the following pieces of context to answer the question at the end.
If you don't know the answer, just say that you don't know, don't try to make up an answer.
Use three sentences maximum and keep the answer as concise as possible.
Always say "thanks for asking!" at the end of the answer.

{context}

Question: {question}

Helpful Answer:"""
custom_rag_prompt = PromptTemplate.from_template(template)

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | custom_rag_prompt
    | llm
    | StrOutputParser()
)

rag_chain.invoke("What is Task Decomposition?")
```

```python
"Task decomposition breaks big tasks into simpler, manageable steps for an agent to follow. It uses Chain of Thought prompting or other methods to guide the agent's planning process. Thanks for asking!"
```
</details>


# *Reference*

[LangChain Docs](https://python.langchain.com/v0.2/docs/introduction/)
[LangChain KR](https://github.com/teddylee777/langchain-kr/tree/main)

# *Footnotes*

<a name="odbc" class="_footnote">1.</a> Open DataBase Connectivity  
ì‘ìš©í”„ë¡œê·¸ë¨ <span class="_pink _italic">HeidiSQL, SQLyog, etc.</span>ì—ì„œ ë°ì´í„° ì ‘ê·¼ í•  ë•Œ ì–´ë– í•œ DBMS <span class="_pink _italic">Oracle, MySQL, MariaDB, etc.</span>ì— ì˜í•´ ê´€ë¦¬ë˜ê³  ìˆëŠ”ì§€ ì˜ì‹í•  í•„ìš”ê°€ ì—†ìŒ
